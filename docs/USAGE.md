# ComfyGen Usage Guide

Complete guide for using ComfyGen via CLI and MCP server for AI-driven image and video generation.

## Table of Contents

- [Quick Start](#quick-start)
- [CLI Usage](#cli-usage)
  - [Basic Image Generation](#basic-image-generation)
  - [Image-to-Image](#image-to-image)
  - [Video Generation](#video-to-image)
  - [Parameters](#parameters)
  - [Presets](#presets)
  - [Validation](#validation)
  - [Quality-Based Refinement](#quality-based-refinement)
- [MCP Server](#mcp-server)
  - [Setup](#mcp-setup)
  - [Available Tools](#available-tools)
  - [MCP Examples](#mcp-examples)
- [Workflows](#workflows)
- [Prompt Engineering](#prompt-engineering)
- [Error Handling](#error-handling)
- [Gallery Browser](#gallery-browser)

---

## Quick Start

### Simple Image Generation

```bash
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "a sunset over mountains, cinematic lighting" \
    --output /tmp/sunset.png
```

The image will be:
1. Generated by ComfyUI on moira
2. Saved locally to `/tmp/sunset.png`
3. Uploaded to MinIO at `http://192.168.1.215:9000/comfy-gen/<timestamp>_sunset.png`

### Viewing Images

Images are viewable directly in browser:
```
http://192.168.1.215:9000/comfy-gen/<filename>.png
```

List all images:
```bash
curl -s http://192.168.1.215:9000/comfy-gen/ | grep -oP '(?<=<Key>)[^<]+'
```

---

## CLI Usage

### Basic Image Generation

```bash
# SD 1.5 generation
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "detailed portrait of a warrior, highly detailed" \
    --negative-prompt "blurry, low quality, watermark" \
    --output /tmp/warrior.png

# With custom parameters
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "landscape with mountains" \
    --steps 50 \
    --cfg 7.5 \
    --width 768 \
    --height 512 \
    --seed 12345 \
    --output /tmp/landscape.png

# Using a preset
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "detailed fantasy scene" \
    --preset high-quality \
    --output /tmp/scene.png
```

### Image-to-Image

Transform existing images with prompts:

```bash
# Basic transformation
python3 generate.py \
    --workflow workflows/sd15-img2img.json \
    --input-image /path/to/source.png \
    --prompt "oil painting style" \
    --denoise 0.7 \
    --output /tmp/artistic.png

# From URL with preprocessing
python3 generate.py \
    --workflow workflows/sd15-img2img.json \
    --input-image "http://192.168.1.215:9000/comfy-gen/previous.png" \
    --resize 512x512 \
    --crop cover \
    --denoise 0.5 \
    --prompt "watercolor painting, soft colors" \
    --output /tmp/watercolor.png
```

**Denoise Guide:**
- **0.3**: Very subtle changes
- **0.5**: Moderate changes, keeps structure
- **0.7**: Significant transformation
- **0.9**: Heavy transformation

### Video Generation

```bash
# Text-to-video
python3 generate.py \
    --workflow workflows/wan22-t2v.json \
    --prompt "drone shot flying over coastal highway, waves crashing, cinematic" \
    --output /tmp/coastal.mp4

# Image-to-video (animate existing image)
python3 generate.py \
    --workflow workflows/wan22-i2v.json \
    --input-image /path/to/photo.png \
    --prompt "camera slowly zooms in, subtle movement" \
    --output /tmp/animated.mp4

# With LoRAs
python3 generate.py \
    --workflow workflows/wan22-t2v.json \
    --prompt "dancer performing, dynamic movement" \
    --lora "BoobPhysics_WAN_v6.safetensors:0.7" \
    --lora "BounceHighWan2_2.safetensors:0.6" \
    --output /tmp/dance.mp4
```

### Parameters

| Parameter | Range | Default | Effect |
|-----------|-------|---------|--------|
| `--steps` | 1-150 | 20 | Sampling steps (more = finer detail) |
| `--cfg` | 1.0-20.0 | 7.0 | Prompt adherence (higher = stricter) |
| `--seed` | -1 or int | random | Random seed for reproducibility |
| `--width` | 64-2048 | 512 | Output width (divisible by 8) |
| `--height` | 64-2048 | 512 | Output height (divisible by 8) |
| `--sampler` | string | varies | Sampler algorithm |
| `--scheduler` | string | normal | Noise scheduler |
| `--denoise` | 0.0-1.0 | 1.0 | Denoising strength (img2img) |

**Samplers:**
- `euler` - Fast, simple, good for drafts
- `euler_ancestral` - Adds randomness
- `dpmpp_2m` - Fast with good quality
- `dpmpp_2m_sde` - Slower but higher quality

**Schedulers:**
- `normal` - Standard linear schedule
- `karras` - Better detail preservation
- `exponential` - Alternative distribution

### Presets

Use `--preset` for predefined parameter combinations:

| Preset | Steps | CFG | Sampler | Use Case |
|--------|-------|-----|---------|----------|
| `draft` | 10 | 5.0 | euler | Quick previews |
| `balanced` | 20 | 7.0 | euler_ancestral | Default quality/speed |
| `high-quality` | 50 | 7.5 | dpmpp_2m_sde | Final outputs |
| `fast` | 15 | 7.0 | dpmpp_2m | Good speed/quality |
| `ultra` | 100 | 8.0 | dpmpp_2m_sde | Maximum quality |

Example:
```bash
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "detailed scene" \
    --preset high-quality \
    --output scene.png
```

Override specific parameters:
```bash
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "robot" \
    --preset balanced \
    --seed 42 \
    --width 768 \
    --output robot.png
```

### Validation

ComfyGen includes CLIP-based validation to detect quality issues and auto-retry with adjusted prompts.

```bash
# Just validate (no retry)
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "a red Porsche 911" \
    --output /tmp/car.png \
    --validate

# Validate with auto-retry
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "(Porsche 911:2.0) single car, one car only" \
    --negative-prompt "multiple cars, duplicate, cloned" \
    --output /tmp/car.png \
    --validate --auto-retry --retry-limit 3
```

**Validation Options:**

| Flag | Type | Default | Description |
|------|------|---------|-------------|
| `--validate` | Boolean | False | Run validation after generation |
| `--auto-retry` | Boolean | False | Retry if validation fails |
| `--retry-limit` | Integer | 3 | Maximum retry attempts |
| `--positive-threshold` | Float | 0.25 | Minimum CLIP score (0-1) |

**CLIP Score Interpretation:**
- **< 0.20**: Poor semantic match
- **0.20-0.25**: Marginal match
- **0.25-0.35**: Acceptable (default threshold)
- **> 0.35**: Good semantic match

### Quality-Based Refinement

ComfyGen includes iterative refinement that automatically retries generation with adjusted parameters until a quality threshold is met. This mimics how DALL-E/ChatGPT achieves consistent quality.

**Basic Usage:**

```bash
# Progressive refinement (increase steps/cfg on retry)
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "a sunset over mountains" \
    --quality-threshold 7.5 \
    --max-attempts 3 \
    --retry-strategy progressive \
    --output /tmp/sunset.png
```

**Retry Strategies:**

| Strategy | Description | When to Use |
|----------|-------------|-------------|
| `progressive` | Increases steps and CFG on each retry | Default - general quality improvement |
| `seed_search` | Tries different seeds with same params | When variation needed |
| `prompt_enhance` | Adds quality tags to prompt | When prompt adherence is low |

**Progressive Strategy Example:**
```
Attempt 1: steps=30, cfg=7.0
Attempt 2: steps=50, cfg=7.5
Attempt 3: steps=80, cfg=8.0
```

**Seed Search Example:**
```
Attempt 1: seed=42, steps=50
Attempt 2: seed=1337, steps=50
Attempt 3: seed=9999, steps=50
```

**Prompt Enhancement Example:**
```
Attempt 1: "a landscape"
Attempt 2: "a landscape, highly detailed, sharp focus"
Attempt 3: "a landscape, masterpiece, best quality, 8K, ultra detailed, sharp focus"
```

**Quality Scoring:**

Images are scored on a 0-10 scale across multiple dimensions:

| Dimension | Weight | What It Measures |
|-----------|--------|------------------|
| Prompt Adherence | 25% | Semantic match to prompt (CLIP) |
| Technical Quality | 30% | Artifacts, noise, blur |
| Aesthetic Quality | 25% | Visual appeal, composition |
| Detail Quality | 20% | Fine details, sharpness |

**Composite Score Grades:**
- **A (8.0-10.0)**: Production ready
- **B (6.5-7.9)**: Good quality
- **C (5.0-6.4)**: Acceptable
- **D (3.0-4.9)**: Poor quality
- **F (0.0-2.9)**: Failed

**Refinement Options:**

| Flag | Type | Default | Description |
|------|------|---------|-------------|
| `--quality-threshold` | Float | 7.0 | Minimum quality score (0-10) |
| `--max-attempts` | Integer | 3 | Maximum generation attempts |
| `--retry-strategy` | Choice | progressive | Retry strategy to use |

**Advanced Example:**

```bash
# High quality with seed search
python3 generate.py \
    --workflow workflows/flux-dev.json \
    --prompt "detailed portrait of a warrior" \
    --negative-prompt "blurry, low quality" \
    --quality-threshold 8.0 \
    --max-attempts 5 \
    --retry-strategy seed_search \
    --steps 50 \
    --cfg 7.5 \
    --output /tmp/warrior.png
```

**Metadata Tracking:**

Refinement history is automatically saved in JSON metadata:

```json
{
  "quality": {
    "composite_score": 7.8,
    "grade": "B",
    "prompt_adherence": 8.2,
    "technical": 7.5,
    "aesthetic": 7.9,
    "detail": 7.6
  },
  "refinement": {
    "attempt": 2,
    "max_attempts": 3,
    "strategy": "progressive",
    "previous_scores": [5.2, 7.8],
    "final_status": "success"
  }
}
```

---

## MCP Server

The MCP (Model Context Protocol) server provides 25 AI-ready tools for image and video generation, allowing AI assistants like Claude to control ComfyGen.

### MCP Setup

Add to your MCP client configuration (VS Code, Claude Desktop, etc.):

```json
{
  "mcpServers": {
    "comfy-gen": {
      "command": "python3",
      "args": ["/path/to/comfy-gen/mcp_server.py"],
      "env": {
        "COMFYUI_HOST": "http://192.168.1.215:8188",
        "MINIO_ENDPOINT": "192.168.1.215:9000",
        "MINIO_BUCKET": "comfy-gen",
        "CIVITAI_API_KEY": "${CIVITAI_API_KEY}"
      }
    }
  }
}
```

**Environment Variables:**
- `COMFYUI_HOST` - ComfyUI server URL (default: http://192.168.1.215:8188)
- `MINIO_ENDPOINT` - MinIO endpoint (default: 192.168.1.215:9000)
- `MINIO_BUCKET` - MinIO bucket name (default: comfy-gen)
- `CIVITAI_API_KEY` - Optional CivitAI API key for model downloads

### Available Tools

The MCP server provides tools across 7 categories:

#### 1. Service Management (4 tools)

- `start_comfyui_service()` - Start ComfyUI server
- `stop_comfyui_service()` - Stop ComfyUI server
- `restart_comfyui_service()` - Restart ComfyUI server
- `check_comfyui_service_status()` - Check server status

#### 2. Image Generation (2 tools)

**`generate_image(prompt, ...)`**

Generate image from text prompt with optional progress tracking and local file output.

Args:
- `prompt` (str): What to generate
- `negative_prompt` (str): What to avoid (default: "blurry, low quality, watermark")
- `model` (str): Model to use - sd15, flux, sdxl (default: sd15)
- `width` (int): Image width (default: 512)
- `height` (int): Image height (default: 512)
- `steps` (int): Sampling steps (default: 20)
- `cfg` (float): CFG scale (default: 7.0)
- `sampler` (str): Sampler algorithm (default: euler)
- `scheduler` (str): Scheduler type (default: normal)
- `seed` (int): Random seed, -1 for random (default: -1)
- `output_path` (str): Optional local file path to save image
- `json_progress` (bool): Enable structured progress updates (default: False)

Returns: `{status, url, local_path, prompt_id, metadata, progress_updates}`

**Progress Tracking Example:**
```python
result = await generate_image(
    prompt="a sunset over mountains, cinematic lighting",
    output_path="/tmp/sunset.png",
    json_progress=True
)

# Access progress updates
for update in result["progress_updates"]:
    if update["type"] == "progress":
        print(f"Step {update['step']}/{update['max_steps']} ({update['percent']}%)")

# Image saved to both:
print(f"MinIO URL: {result['url']}")
print(f"Local file: {result['local_path']}")
```

**`img2img(input_image, prompt, ...)`**

Transform existing image with prompt guidance.

Args:
- `input_image` (str): URL or path to input image
- `prompt` (str): Transformation prompt
- `negative_prompt` (str): What to avoid
- `denoise` (float): Strength 0.0-1.0 (default: 0.7)
- Additional parameters same as `generate_image`

Returns: `{status, url, prompt_id, metadata}`

#### 3. Video Generation (2 tools)

**`generate_video(prompt, ...)`**

Generate video from text using Wan 2.2 T2V.

Args:
- `prompt` (str): Video description
- `negative_prompt` (str): What to avoid
- `width` (int): Video width (default: 832)
- `height` (int): Video height (default: 480)
- `frames` (int): Number of frames (default: 81)
- `fps` (int): Frames per second (default: 16)
- `steps` (int): Sampling steps (default: 30)
- `cfg` (float): CFG scale (default: 6.0)
- `seed` (int): Random seed (default: -1)

Returns: `{status, url, prompt_id, metadata}`

**`image_to_video(input_image, prompt, ...)`**

Animate image to video using Wan 2.2 I2V.

Args:
- `input_image` (str): URL or path to input image
- `prompt` (str): Motion description
- `motion_strength` (float): Movement amount 0.0-1.0+ (default: 1.0)
- Additional parameters same as `generate_video`

Returns: `{status, url, prompt_id, metadata}`

#### 4. Model Management (6 tools)

- `list_models()` - List installed checkpoint models
- `list_loras()` - List installed LoRAs with compatibility info
- `get_model_info(model_name)` - Get detailed metadata about a model
- `suggest_model(task, style, subject)` - Recommend best model for a task
- `suggest_loras(prompt, model, max_suggestions)` - Recommend LoRAs based on prompt
- `search_civitai(query, model_type, ...)` - Search CivitAI for models and LoRAs

#### 5. Gallery & History (4 tools)

- `list_images(limit, prefix, sort)` - Browse generated images
- `get_image_info(image_name)` - Get generation parameters for an image
- `delete_image(image_name)` - Remove image from storage
- `get_history(limit)` - Get recent generations with full parameters

#### 6. Prompt Engineering (3 tools)

- `build_prompt(subject, style, setting)` - Construct a well-formed prompt
- `suggest_negative(model_type)` - Get recommended negative prompt
- `analyze_prompt(prompt)` - Analyze prompt and suggest improvements

#### 7. Progress & Control (5 tools)

- `get_progress(prompt_id)` - Get current generation progress
- `cancel(prompt_id)` - Cancel current or specific generation
- `get_queue()` - View queued jobs
- `get_system_status()` - Get GPU/VRAM/server health info
- `validate_workflow(model, prompt, width, height)` - Validate workflow without generating (dry run)

**Progress Tracking:**
```python
# Start generation
result = await generate_image(prompt="test", json_progress=False)

# Poll for progress
progress = await get_progress(result["prompt_id"])
# Returns: {"status": "running", "position": "current", ...}
```

**Dry Run Validation:**
```python
# Validate before generating
validation = await validate_workflow(
    model="sd15",
    prompt="test",
    width=512,
    height=512
)

if validation["is_valid"]:
    # Proceed with actual generation
    result = await generate_image(...)
else:
    print(f"Validation errors: {validation['errors']}")
    print(f"Missing models: {validation['missing_models']}")
```

### MCP Examples

**Simple Image Generation:**
```python
result = await generate_image(
    prompt="a sunset over mountains, highly detailed, 8k",
    width=768,
    height=512,
    steps=25
)
# Returns: {"status": "success", "url": "http://...", ...}
```

**Intelligent Model Selection:**
```python
# Get model recommendation
model = await suggest_model(task="portrait", style="realistic")

# Get LoRA suggestions
loras = await suggest_loras(
    prompt="woman portrait with detailed face",
    model=model["recommended"]
)

# Generate with suggestions
result = await generate_image(
    prompt="woman portrait, professional lighting",
    model=model["recommended"]
)
```

**Animated Portrait:**
```python
# Generate base image
image = await generate_image(
    prompt="woman portrait, professional photo",
    width=832,
    height=480
)

# Animate to video
video = await image_to_video(
    input_image=image["url"],
    prompt="subtle head turn, slight smile",
    steps=30
)
```

**Gallery Management:**
```python
# List recent images
images = await list_images(limit=10, sort="newest")

# Get generation details
info = await get_image_info(images["images"][0]["name"])
print(f"Prompt: {info['generation_params']['positive_prompt']}")

# Delete old images
await delete_image("old_image.png")
```

---

## Workflows

ComfyGen includes several pre-built workflows for different tasks:

| Workflow | Type | Input | Output | Time | Use Case |
|----------|------|-------|--------|------|----------|
| `flux-dev.json` | T2I | None | 512x512 PNG | 10-15s | Quick image generation |
| `sd15-img2img.json` | I2I | Image | Variable PNG | 10-20s | Image transformation |
| `wan22-t2v.json` | T2V | None | 848x480 MP4 | 2-5min | Video from text |
| `wan22-i2v.json` | I2V | Image | 848x480 MP4 | 2-5min | Animate images |

**Decision Tree:**

```
Need video/animation?
├─ YES → Input image available?
│         ├─ YES → wan22-i2v.json (Image-to-Video)
│         └─ NO  → wan22-t2v.json (Text-to-Video)
│
└─ NO  → Transform existing image?
          ├─ YES → sd15-img2img.json
          └─ NO  → flux-dev.json (SD 1.5)
```

---

## Prompt Engineering

### Prompt Catalog

A structured collection of prompt patterns is available in `prompt_catalog.yaml`:

- **Quality Boosters** - Phrases to enhance image quality
- **Negative Presets** - Curated negative prompts by use case (minimal, standard, comprehensive)
- **Style Modifiers** - Photography, pixel art, vector, illustration styles
- **Templates** - Ready-to-use prompts for common scenarios (automotive, game icons, portraits)
- **Model-Specific Adjustments** - CFG and step recommendations by model

Use the catalog to build consistent, high-quality prompts.

### CRITICAL: Use Detailed, Verbose Prompts

Models can handle paragraph-length prompts with extensive detail. More specific descriptions produce better results.

**Basic Structure (Minimum):**
```
[subject], [style], [lighting], [quality modifiers]
```

**Example (basic):**
```
a red Porsche 911 on a mountain road, cinematic photography, golden hour lighting, highly detailed, 8k
```

**Recommended: Detailed Paragraph-Style Prompts:**

```
A sleek red Porsche 911 GT3 sports car driving along a winding mountain road carved into 
rocky cliffs, photographed during golden hour with warm amber sunlight streaming through 
gaps in the mountains, casting long dramatic shadows across the asphalt. The car is 
captured in motion from a three-quarter front angle, showing the aggressive front fascia 
and aerodynamic bodywork in sharp detail. The background features towering pine trees and 
distant snow-capped peaks bathed in soft orange-pink evening light. Professional 
automotive photography style reminiscent of Top Gear or Motor Trend magazine shoots, 
shot with a wide-angle lens (24mm), shallow depth of field to blur the background while 
keeping the car in tack-sharp focus, cinematic color grading with rich warm tones, 8K 
resolution with meticulous attention to reflections on the car's paint and glinting 
highlights on chrome accents.
```

**Why detailed prompts work better:**
- Reduces ambiguity
- Layers constraints for better control
- Uses redundant phrasing to reinforce critical concepts
- Provides visual anchors (magazine references, specific lenses)
- Specifies exactly what you want

### Negative Prompts

**Default negative prompt (SD 1.5):**
```
bad quality, blurry, low resolution, watermark, text, deformed, ugly, duplicate
```

**For photorealism:**
```
cartoon, anime, illustration, painting, sketch, 3d render, CGI, digital art, 
cel shaded, low poly, unrealistic, stylized, painterly
```

**For avoiding duplicates:**
```
multiple objects, duplicate, cloned, ghosting, mirrored, two cars, extra person, 
multiple subjects, repeated elements
```

**For perspective control (sprites, top-down):**
```
perspective, side view, diagonal, isometric, 3D, angled, tilted, depth, 
foreshortening, vanishing point, horizon line
```

### Video Prompts (Wan 2.2)

**Good structure:**
```
[action/motion], [subject], [setting], [camera movement]
```

**Example:**
```
a car driving along a coastal highway, waves crashing, drone shot following
```

**Note:** Wan 2.2 workflows typically do not use negative prompts.

---

## Error Handling

### Common Errors

| Error | Cause | Solution |
|-------|-------|----------|
| "Cannot connect to server" | ComfyUI down | Start via `scripts/start_comfyui.py` |
| "Model not found" | Missing model | Check MODEL_REGISTRY.md |
| "Invalid JSON" | Malformed workflow | Re-export from ComfyUI |
| "Input image not found" | Wrong path | Use absolute paths |
| "MinIO upload failed" | MinIO down | Check 192.168.1.215:9000 |

### Exit Codes

- **0**: Success
- **1**: Generation or runtime failure
- **2**: Configuration error (server down, missing models)

### ComfyUI Not Responding

```bash
# Check status
curl -s http://192.168.1.215:8188/system_stats

# Start ComfyUI
ssh moira "C:\\Users\\jrjen\\comfy\\.venv\\Scripts\\python.exe C:\\Users\\jrjen\\comfy-gen\\scripts\\start_comfyui.py"
```

### Model Not Found

1. Check exact filename in MODEL_REGISTRY.md
2. Verify model exists: `ssh moira "dir C:\\Users\\jrjen\\comfy\\models\\checkpoints"`
3. Model names are case-sensitive

### Best Practices

1. **Always check server availability first**
2. **Use dry-run mode for new workflows**: `--dry-run`
3. **Handle missing models gracefully**
4. **Use automatic retry for transient failures** (built-in)
5. **Clean up on cancellation**

---

## Gallery Browser

### Local Gallery Server

Browse generated images with thumbnails and metadata:

```bash
python3 scripts/gallery_server.py
# Open http://localhost:8080
```

**Features:**
- Grid view with thumbnails
- Search by prompt text
- Filter: All / With LoRA / Validated
- Sort: Newest / Oldest
- Click to view full-size
- Shows: seed, steps, cfg, LoRAs, validation score

### MinIO Console

Official MinIO web interface for file management:

```
http://192.168.1.215:9001
Login: minioadmin / minioadmin
```

### Direct URL Access

Images are publicly accessible:
```
http://192.168.1.215:9000/comfy-gen/<filename>.png
```

Metadata sidecars:
```
http://192.168.1.215:9000/comfy-gen/<filename>.png.json
```

---

## See Also

- [MODEL_REGISTRY.md](MODEL_REGISTRY.md) - Available models and LoRAs
- [API_REFERENCE.md](API_REFERENCE.md) - Internal module documentation
- [ARCHITECTURE.md](ARCHITECTURE.md) - System design and workflows
