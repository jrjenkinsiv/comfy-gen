{
  "1": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Wan 2.2 I2V Diffusion Model"
    }
  },
  "2": {
    "inputs": {
      "clip_name1": "oldt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "clip_name2": "oldt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "flux"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "Load Text Encoders"
    }
  },
  "3": {
    "inputs": {
      "text": "the person starts walking forward",
      "clip": [
        "2",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Motion Prompt"
    }
  },
  "4": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "5": {
    "inputs": {
      "image": "input_image.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Input Image"
    }
  },
  "6": {
    "inputs": {
      "pixels": [
        "5",
        0
      ],
      "vae": [
        "4",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "Encode Input Image"
    }
  },
  "7": {
    "inputs": {
      "model": [
        "1",
        0
      ],
      "clip": [
        "2",
        0
      ],
      "lora_name": "wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
      "strength_model": 1.0,
      "strength_clip": 1.0
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load 4-Step Acceleration LoRA"
    }
  },
  "8": {
    "inputs": {
      "seed": 0,
      "steps": 4,
      "cfg": 1.0,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.95,
      "model": [
        "7",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "3",
        0
      ],
      "latent_image": [
        "6",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Sample Video"
    }
  },
  "9": {
    "inputs": {
      "samples": [
        "8",
        0
      ],
      "vae": [
        "4",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "Decode Video"
    }
  },
  "10": {
    "inputs": {
      "frame_rate": 8,
      "loop_count": 0,
      "filename_prefix": "wan22_i2v",
      "format": "video/h264-mp4",
      "pingpong": false,
      "save_output": true,
      "images": [
        "9",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Save Video"
    }
  },
  "_workflow_metadata": {
    "workflow_name": "Wan 2.2 Image-to-Video",
    "description": "Animate existing images with motion using Wan 2.2 high noise model",
    "model": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
    "input_requirements": "Requires input image (--input-image flag)",
    "text_encoder": "oldt5_xxl_fp8_e4m3fn_scaled.safetensors",
    "vae": "wan_2.1_vae.safetensors",
    "acceleration_lora": "wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
    "output_specs": {
      "resolution": "848x480",
      "frames": 81,
      "fps": 8,
      "duration": "~10 seconds",
      "format": "MP4"
    },
    "generation_params": {
      "steps": 4,
      "cfg": 1.0,
      "sampler": "dpmpp_2m"
    },
    "use_case": "Animate static images, add camera movement, create motion from photos",
    "estimated_time": "2-5 minutes on RTX 5090",
    "prompt_tips": [
      "Describe desired motion (pan, zoom, tilt)",
      "Specify camera movement",
      "Focus on action to add to scene",
      "Keep prompts concise and motion-focused"
    ],
    "preprocessing_options": "Input image should match 848x480 or use --resize",
    "nodes_overview": {
      "image_loading": "Load input image",
      "text_encoding": "T5 text encoding for motion prompt",
      "model_loading": "Diffusion model and VAE loading",
      "lora": "Acceleration LoRA (4-step)",
      "sampling": "I2V sampler with image conditioning",
      "vae_decode": "Video VAE decoding",
      "save": "Video output to file"
    }
  }
}