{
  "1": {
    "inputs": {
      "ckpt_name": "v1-5-pruned-emaonly-fp16.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "text": "oil painting style",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Positive Prompt"
    }
  },
  "3": {
    "inputs": {
      "text": "",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Negative Prompt"
    }
  },
  "4": {
    "inputs": {
      "image": "input_image.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Input Image"
    }
  },
  "5": {
    "inputs": {
      "pixels": [
        "4",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "Encode Input Image"
    }
  },
  "6": {
    "inputs": {
      "seed": 0,
      "steps": 30,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "normal",
      "denoise": 0.7,
      "model": [
        "1",
        0
      ],
      "positive": [
        "2",
        0
      ],
      "negative": [
        "3",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "7": {
    "inputs": {
      "samples": [
        "6",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "8": {
    "inputs": {
      "filename_prefix": "sd15_img2img",
      "images": [
        "7",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "_workflow_metadata": {
    "workflow_name": "SD 1.5 Image-to-Image",
    "description": "Transform existing images with text prompts using Stable Diffusion 1.5",
    "model": "v1-5-pruned-emaonly-fp16.safetensors",
    "input_requirements": "Requires input image (--input-image flag)",
    "output_resolution": "Matches input (or --resize target)",
    "denoise_range": "0.3-0.5 (subtle), 0.7-0.9 (creative)",
    "use_case": "Image transformation, style transfer, modifications",
    "estimated_time": "10-20 seconds on RTX 5090",
    "preprocessing_options": "Supports --resize, --crop, --denoise",
    "nodes": {
      "1": "Checkpoint Loader - Loads SD 1.5 model",
      "2": "Positive Prompt - Transformation style/target",
      "3": "Negative Prompt - What to avoid in transformation",
      "5": "Load Image - Loads input image from ComfyUI input folder",
      "6": "VAE Encode - Converts input image to latent space",
      "7": "KSampler - Performs diffusion with denoise control",
      "8": "VAE Decode - Converts result back to pixel image",
      "9": "Save Image - Saves output"
    }
  }
}